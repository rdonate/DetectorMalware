from src.extract_features.extract_features import extract_features
from src.misc.splits import split_Source_Trainning,split_Source_Test
from src.model.create_model import create_Model
from src.model.prediction import prediction
from envparse import env
from multiprocessing import Pool
import datetime
from functools import partial
from src.mongo.database import DataBaseMongo


def main():
    start=datetime.datetime.now().time().strftime('%H:%M:%S')
    print(start)
    ip_Server_Mongo = env.str('IP_SERVER_MONGO', default='172.16.0.2')
    db_Name = env.str('DB_NAME', default='tfg')
    order = env.int('ORDER_EXTRACT_FEUTURES_ASM', default=4)
    dir_Data_Raw=env.str('DIR_DATA_RAW', default='/data/raw')
    seed=env.int('SEED',default=1234)
    thread=env.int('THREAD',default=4)
    sample = env.bool('SAMPLE', default=False)
    perform_Method=env.str('PERFORM_METHOD', default='ALL')
    names_Collections=('total', 'features', 'rankingFeautures')
    prefix_collections='train'
    dir_OriginDataTrain=dir_Data_Raw+'DataBase/trainLabels.csv'
    if perform_Method=='EXTRACT' or perform_Method=='ALL':
        db = DataBaseMongo(ip_Server_Mongo, db_Name)
        for colection in names_Collections:
            db.selectCollection(prefix_collections+'_'+colection).drop()
        del db
        with open(dir_OriginDataTrain,'r') as file:
            text = file.read()
        sources = map(split_Source_Trainning, text.split('\n')[1:-1])
        if sample:
            from src.misc.sample import selectSample
            percentage_sample = env.float('PERCENTAGE_SAMPLE', default=5)
            sources = selectSample(percentage_sample,seed,sources)
            del percentage_sample
        del sample
        # for source in sources:
        #     extracts_features_train(source)
        pool=Pool(thread)
        extracts_features_train = partial(extract_features, ip_Server_Mongo, db_Name, dir_Data_Raw + 'DataBase/', prefix_collections, order)
        pool.map(extracts_features_train, sources)
        del extracts_features_train
    if perform_Method == 'MODEL' or perform_Method == 'MODEL_PREDICT' or perform_Method == 'ALL':
        model = create_Model(prefix_collections, ip_Server_Mongo, db_Name,names_Collections,dir_OriginDataTrain,split_Source_Trainning)
    if perform_Method == 'PREDICT' or perform_Method == 'MODEL_PREDICT' or perform_Method == 'ALL':
        dir_OriginDataTest = dir_Data_Raw+'DataBase/sampleSubmission.csv'
        prefix_collections = 'test'
        db = DataBaseMongo(ip_Server_Mongo, db_Name)
        for colection in names_Collections:
            db.selectCollection(prefix_collections + '_' + colection).drop()
        del db
        with open(dir_OriginDataTest,'r') as file:
            text = file.read()
        sources = map(split_Source_Test, text.split('\n')[1:-1])
        pool = Pool(thread)
        extracts_features_test = partial(extract_features, ip_Server_Mongo, db_Name, dir_Data_Raw + 'DataBase/', prefix_collections, order)
        pool.map(extracts_features_test, sources)
        prediction(model,dir_OriginDataTest)
    finish=datetime.datetime.now().time().strftime('%H:%M:%S')
    print(finish)
    print(datetime.datetime.strptime(finish,'%H:%M:%S') - datetime.datetime.strptime(start,'%H:%M:%S'))

if __name__ == '__main__':
    main()
