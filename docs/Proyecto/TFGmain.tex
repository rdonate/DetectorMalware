%\documentclass[spanish,twoside,12pt]{tfg-esiiab}
\documentclass[spanish,twoside,12pt,a4paper]{book}
\usepackage{tfg-esiiab}

% Nuestros paquetes
\usepackage{subcaption}

\usepackage{color}
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\usepackage{listings}
\lstset{ %
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\ttfamily,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen}\ttfamily,    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=none,	                   % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue}\ttfamily,       % keyword style
  language=C,                      % the language of the code
  otherkeywords={*,...},           % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=1,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve}\ttfamily,     % string literal style
  tabsize=4,	                       % sets default tabsize to 4 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}

\usepackage{algorithm,algpseudocode}
\usepackage{pgfgantt}

\title{Detección y Clasificación de Malware usando técnicas inteligentes}
\author{Rubén Donate Serrano}


\begin{document}

%De esta forma sale nombre de Tabla en vez de Cuadro
\renewcommand\tablename{Tabla}
\renewcommand\listtablename{ÍNDICE DE TABLAS}

\renewcommand\listfigurename{ÍNDICE DE FIGURAS}

\supervisor{José Luis Martínez Martínez}
\cosupervisor{José Miguel Puerta Callejón}

\maketitle

\frontmatter %Activa la numeración romana

\begin{autoria}

Yo, pepito perez con DNI...... , declaro que soy el único autor del trabajo fin de grado titulado ......  y que el citado trabajo no infringe las leyes en vigo sobre propiedad intelectual y que todo el material no original contenido en dicho trabajo está apropiadamente atribuido a sus legítimos autores.


Albacete, a.....


Fdo: pepito perez

\end{autoria}

\begin{resumen} %%Resumen del documento
Este documento pretende ser un manual sobre el uso del paquete de
\LaTeXe{} \texttt{tfg-esiiab.sty}. Este paquete de estilo da el
formato al documento según las normas de estilo establecidas por la
Escuela Superior de Ingeniería Informática de Albacete, perteneciente
a la Universidad de Castilla-la Mancha.
\end{resumen}

\begin{dedicatoria} %Inclusión de la dedicatoria
A mis compañeros y alumnos.
\end{dedicatoria}

\begin{agradece} %%Agradecimientos
Agradecer a todas aquellas personas que me han ayudado a aprender
\LaTeXe{}, bien sea por lo que me enseñaron, o por las preguntas que
me transmitieron y que yo intenté solucionar.
\end{agradece}

\tableofcontents

\clearpage
\listoffigures
\addcontentsline{toc}{section}{Lista de Figuras} 
\clearpage
\listoftables
\addcontentsline{toc}{section}{Lista de Tablas} 
\thispagestyle{empty}\cleardoublepage

\mainmatter %Activa la numeración arábica.

\chapter{INTRODUCCIÓN}

\section{Motivación}

\section{Objetivos}

\section{Estructura de la memoria}

\chapter{TÉCNICAS UTILIZADAS}

\begin{enumerate}
	\item ngram\label{ngram} 
	\item randomForrestClassifier \label{randomForrestClassifier}
	\item numpy \label{numpy}
\end{enumerate}

\chapter{ANTECEDENTES Y ESTADO DE LA CUESTIÓN}

Para el proyecto de Kaggle que se ha seleccionado para este Trabajo de Final de Grado, se he realizado una búsqueda para intentar encontrar soluciones presentadas para este reto. De esta búsqueda, se ha conseguido encontrar varias soluciones presentadas para este mismo reto. A continuación, se explicaran las soluciones presentadas que se han encontrado para este reto de Kaggle.\\

\section{Solución 1}

Esta primera solución que se va a comentar, fue realizada por Vishnu Chevli \cite{VishnuChevli} y en la clasificación del Reto de Kaggle obtuvo una resultado en el ranking publico de $0.023121984$ en la posición 90 y en el ranking privado $0.018856579$ en la posición 72.\\

Esta solución se desarrollo para que pudiera ser ejecutada de manera indistinta en Python 2 y Python 3, es muy sencilla y consiste en:\\

En primero lugar, se descomprimir las dos bases de datos que se proporcionan. Estas bases de datos contienen dos tipos de ficheros que contienen la información obtenida de IDA al desensamblar la muestras en dos formatos, siendo estos formatos ASM para los ficheros con extensión .asm y binario en formato hexadecimal para los ficheros con extensión .bytes. Para esta solución solo se utilizaran los ficheros con extensión .bytes. Después, estos ficheros son nuevamente comprimidos en formato gzip de manera separada y separando las bases de datos en dos carpetas distintas. El motivo de realizar esto es para ahorrar espacio en disco, ya que el espacio de la base de datos completas con todos los tipos de ficheros sin comprimir es de aproximadamente 1 Tb.\\

El siguiente paso, consiste en extraer las características de los ficheros que se han generado en el paso anterior. Esta extracción consiste en generar un array donde cada posición corresponde a cada uno de los posibles uno ngrama \ref{ngram}, formado por dos caracteres en formato hexadecimal, incluyendo el ngram '??'\ que indica que el valor correspondiente no esta mapeado, y contar las veces que aparece cada uno de ellos en el fichero, para concluir, guardando los resultados en un fichero csv de manera separada para cada una de las bases de datos. Este proceso ser realizara de manera conjunta para las dos bases de datos y de manera paralela para 2 ficheros.\\

El siguiente paso, es construir el modelo que para este caso es un RandomForrestClassifier \ref{randomForrestClassifier}. Para ello, lo primero se tiene que realizar es obtener la clase para cada uno de los fichero, para lo cual se tiene que abrir y recorrer el fichero 'trainLabels.csv'\ que se proporciona y almacenar la información del mismo en un diccionario que posteriormente se utilizará. A continuar, se crea una matriz con numpy \ref{numpy} de tamaño el numero de ficheros de la base de datos de train por el número de uno ngramas \ref{ngram} mas uno adicional para la clase, en este caso $10868 * 258$. Estos datos son obtenidos del fichero csv correspondiente a la base de datos de train para los valores de los uno ngramas \ref{ngram} y del diccionario creado anteriormente para la clase.  Después, se crea el modelo con los valores por defecto, excepto la semilla que utiliza $123$, el número de hilos que utiliza $5$ y el nivel de información que muestra que utiliza la mas detallada $2$. Por ultimo, solo queda entrenar el modelo pasando le la matriz de numpy \ref{numpy} separando las características y la clase, o lo que es lo mismo la matriz sin la ultima columna y la ultima columna por separado, siendo esta ultima columna la clase.\\

Para terminar, solo nos queda realizar la previsión para la base de datos de test. Para ello, ahí que repetir el proceso de recuperar las características creando una matriz con numpy \ref{numpy} pero en este caso sin añadir un columna para la clase, también se crea un array donde se almacena el nombre del fichero en el mismo indice que la fila de la matriz, esto es así porque la predicción ha de ser identificada con es valor. Lo siguiente, es realizar la predicción para la base de datos de test. Para concluir, escribiendo los resultados en un fichero comprimido en el que guarda la información con el formato que se nos proporciona en el ejemplo, siendo este el id del fichero seguido de la probabilidad que sea cada una de las clases separado todo por comas.\\

\section{Solución 2}

Esta segunda solución que se va a comentar, fue realizada de manera conjunta por Mikhail Trofimov, Dmitry Ulyanov y Stanislav Semenov \cite{MikhailTrofimovDmitryUlyanovStanislavSemenov} y en la clasificación del Reto de Kaggle obtuvo una resultado en el ranking publico de $0.005984430$ en la posición 14 y en el ranking privado $0.003969846$ en la posición 3.\\

Esta solución es mucho mas compleja como se puede suponer de la posición que obtuvo en el ranking, de echo según sus creadores utilizaron una maquina con 16 cores y 120 Gb de RAM para su ejecución. Ahora, se analizará en que consiste esta solución:\\

Lo primero que realizar es crear los directorios, para ello existe un script en bash llamado 'create\_dirs.sh'\ para generar los directorios necesarios. A continuación, toca ejecutar otro script en bash llamado 'main.sh'\ para la extracción de las características que posteriormente se va a utilizar para construir el modelo. Este proceso de extracción consisten en:\\



\chapter{METODOLOGÍA Y DESARROLLO}

\chapter{EXPERIMENTOS Y RESULTADOS}

\chapter{CONCLUSIONES Y PROPUESTAS}

\section{Conclusiones}

\section{Trabajo futuro}

\renewcommand{\refname}{BIBLIOGRAFÍA}


\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,mibibliografia}

%\bibliographystyle{plain}
%\bibliography{mibibliografia}

\addcontentsline{toc}{chapter}{BIBLIOGRAFIA}

\chapter*{CONTENIDO DEL CD}

\end{document}